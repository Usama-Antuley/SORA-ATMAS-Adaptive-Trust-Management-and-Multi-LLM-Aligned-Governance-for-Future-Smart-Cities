# -*- coding: utf-8 -*-
"""weather prediction model.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/14_3LB6eHi5IcSlPD4la5hZXAhVG3IIbU
"""

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import pickle
import torch
import warnings
from sklearn.model_selection import train_test_split, StratifiedKFold
from sklearn.metrics import confusion_matrix, accuracy_score, classification_report
from sklearn.metrics import roc_curve, auc
from xgboost import XGBClassifier
from sklearn.preprocessing import StandardScaler

# Suppressing warnings for cleaner output
warnings.filterwarnings('ignore')

# Loading the dataset with the first row as header (since metadata is removed)
df = pd.read_csv('/content/Weather Data for Training(2014-2025).csv', header=0)
print("Initial DataFrame shape:", df.shape)
print("Sample of initial data:", df.head())
print("Data types:", df.dtypes)

# Filter to only hourly data (timestamps containing 'T')
df = df[df['time'].str.contains('T', na=False)]
print("Shape after filtering hourly data:", df.shape)
print("Sample of filtered data:", df.head())

# Converting time to datetime with ISO8601 format
df['time'] = pd.to_datetime(df['time'], format='ISO8601', errors='coerce')
df = df[df['time'].notna()]  # Drop any invalid datetime rows
print("Shape after datetime conversion:", df.shape)
print("Sample of time column:", df['time'].head())

# Convert numerical columns to float, handling errors
numerical_columns = [
    'temperature_2m (°C)', 'relative_humidity_2m (%)', 'dew_point_2m (°C)',
    'apparent_temperature (°C)', 'precipitation (mm)', 'rain (mm)', 'snowfall (cm)',
    'pressure_msl (hPa)', 'surface_pressure (hPa)', 'cloud_cover (%)',
    'cloud_cover_low (%)', 'cloud_cover_mid (%)', 'cloud_cover_high (%)',
    'et0_fao_evapotranspiration (mm)', 'wind_speed_10m (km/h)', 'wind_speed_100m (km/h)',
    'wind_direction_10m (°)', 'wind_direction_100m (°)', 'wind_gusts_10m (km/h)',
    'soil_temperature_0_to_7cm (°C)', 'soil_temperature_7_to_28cm (°C)', 'sunshine_duration (s)',
    'is_day ()', 'direct_radiation (W/m²)', 'shortwave_radiation (W/m²)',
    'shortwave_radiation_instant (W/m²)', 'direct_radiation_instant (W/m²)'
]
for col in numerical_columns:
    if col in df.columns:
        df[col] = pd.to_numeric(df[col], errors='coerce')
print("Data types after conversion:", df.dtypes)

# Select relevant columns for analysis
relevant_columns = [
    'time',
    'temperature_2m (°C)',
    'precipitation (mm)',
    'relative_humidity_2m (%)',
    'soil_temperature_0_to_7cm (°C)',
    'wind_speed_10m (km/h)',
    'cloud_cover (%)'
]
df = df[relevant_columns]

# Handling missing values (fill NaN with median for numerical columns)
for col in df.columns:
    if df[col].dtype in ['float64', 'int64']:
        print(f"Filling NaN in {col} with median: {df[col].median()}")
        df[col].fillna(df[col].median(), inplace=True)

# Aggregate to daily data
df_daily = df.groupby(df['time'].dt.date).agg({
    'temperature_2m (°C)': 'mean',
    'precipitation (mm)': 'sum',
    'relative_humidity_2m (%)': 'mean',
    'soil_temperature_0_to_7cm (°C)': 'mean',
    'wind_speed_10m (km/h)': 'mean',
    'cloud_cover (%)': 'mean'
}).reset_index()
df_daily['time'] = pd.to_datetime(df_daily['time'])
print("Daily DataFrame shape:", df_daily.shape)
print("Sample of daily data:", df_daily.head())
print("Temperature stats:", df_daily['temperature_2m (°C)'].describe())

# Temperature trends over time
plt.figure(figsize=(12, 6))
plt.plot(df_daily['time'], df_daily['temperature_2m (°C)'], label='Temperature', color='blue', linewidth=2)
plt.title('Mean Temperature Trends Over Time', fontsize=16, pad=15)
plt.xlabel('Date', fontsize=12)
plt.ylabel('Temperature (°C)', fontsize=12)
plt.legend(fontsize=10)
plt.grid(True, linestyle='--', alpha=0.7)
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

# Precipitation distribution
plt.figure(figsize=(12, 6))
precip_data = df_daily['precipitation (mm)']
if precip_data.notna().any() and precip_data.max() > 0:
    plt.hist(precip_data, bins=30, label='Precipitation', alpha=0.7, color='green', edgecolor='black')
    plt.title('Precipitation Distribution in Islamabad', fontsize=16, pad=15)
    plt.xlabel('Precipitation (mm)', fontsize=12)
    plt.ylabel('Count', fontsize=12)
    plt.legend(fontsize=10)
    plt.grid(True, linestyle='--', alpha=0.7)
    plt.tight_layout()
    plt.show()
else:
    print("Warning: No valid precipitation data found for plotting.")

# Correlation heatmap
plt.figure(figsize=(10, 8))
correlation_matrix = df_daily[[col for col in df_daily.columns if col != 'time']].corr()
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f', annot_kws={"size": 10}, cbar_kws={'label': 'Correlation'})
plt.title('Correlation Heatmap of Weather Variables', fontsize=16, pad=20)
plt.tight_layout()
plt.show()

# --- Define threshold constants ---
FLOOD_RAIN_MM = 50.0          # Daily rainfall ≥ 50 mm often linked to flooding risk
HEAVY_RAIN_MM = 20.0          # Heavy rain: ≥ 20 mm/day
RAINY_DAY_MM = 2.5            # Light to moderate rain: ≥ 2.5 mm/day
HEATWAVE_ABS_C = 40.0         # Absolute heatwave threshold
HEATWAVE_ANOM_C = 5.0         # Anomaly: 5°C above long-term mean
SOIL_SAT = 25.0               # Soil temperature indicating high saturation/moisture risk (adjust as needed)

# --- Rule-based labeling ---
def assign_labels(row):
    temp = row['temperature_2m (°C)']
    total_precip = row['precipitation (mm)']
    soil_temp = row['soil_temperature_0_to_7cm (°C)']

    if total_precip >= FLOOD_RAIN_MM or soil_temp >= SOIL_SAT:
        return 'Heavy Rain & Flooding'
    elif total_precip >= HEAVY_RAIN_MM:
        return 'Heavy Rain'
    elif total_precip >= RAINY_DAY_MM:
        return 'Rain'
    elif temp >= HEATWAVE_ABS_C or (temp >= df_daily['temperature_2m (°C)'].mean() + HEATWAVE_ANOM_C):
        return 'Heatwave'
    else:
        return 'Normal'

# Apply labeling
df_daily['label'] = df_daily.apply(assign_labels, axis=1)

# Label distribution
plt.figure(figsize=(10, 6))
sns.countplot(x='label', data=df_daily, palette='Set2', order=df_daily['label'].value_counts().index)
plt.title('Distribution of Weather Conditions in Islamabad', fontsize=16, pad=15)
plt.xlabel('Weather Condition', fontsize=12)
plt.ylabel('Count', fontsize=12)
plt.grid(True, linestyle='--', alpha=0.7)
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

# --- Preparing data for XGBoost ---
label_mapping = {'Normal': 0, 'Rain': 1, 'Heavy Rain': 2, 'Heavy Rain & Flooding': 2, 'Heatwave': 3}
df_daily['label_encoded'] = df_daily['label'].map(label_mapping)

# Printing the DataFrame after changes
print("\nDataFrame after adding pseudo-labels and encoded labels:")
print(df_daily.head(-1))

# Splitting data
features = df_daily[[col for col in df_daily.columns if col in [
    'temperature_2m (°C)', 'precipitation (mm)', 'relative_humidity_2m (%)',
    'soil_temperature_0_to_7cm (°C)', 'wind_speed_10m (km/h)', 'cloud_cover (%)'
]]]
scaler = StandardScaler()
scaled_features = scaler.fit_transform(features)
X = scaled_features
y = df_daily['label_encoded']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Training XGBoost model
xgb_model = XGBClassifier(random_state=42, eval_metric='mlogloss')
xgb_model.fit(X_train, y_train)

# Predictions
y_pred_train = xgb_model.predict(X_train)
y_pred_test = xgb_model.predict(X_test)

# Cross-validation
skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
cv_scores = []

for train_index, test_index in skf.split(X, y):
    X_train_fold, X_test_fold = X[train_index], X[test_index]
    y_train_fold, y_test_fold = y[train_index], y[test_index]
    xgb_model = XGBClassifier(random_state=42, eval_metric='mlogloss')
    xgb_model.fit(X_train_fold, y_train_fold)
    y_pred_fold = xgb_model.predict(X_test_fold)
    cv_scores.append(accuracy_score(y_test_fold, y_pred_fold))

print("\nCross-Validation Accuracy Scores:", cv_scores)
print("Mean CV Accuracy:", np.mean(cv_scores), "±", np.std(cv_scores))

# Train final model on full training data
xgb_model.fit(X_train, y_train)

# Evaluation metrics
print("\nTraining Accuracy:", accuracy_score(y_train, y_pred_train))
print("Testing Accuracy:", accuracy_score(y_test, y_pred_test))
print("\nClassification Report (Test Set):")
print(classification_report(y_test, y_pred_test, target_names=['Normal', 'Rain', 'Heavy Rain', 'Heatwave']))

# Confusion matrix
cm = confusion_matrix(y_test, y_pred_test)
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Normal', 'Rain', 'Heavy Rain', 'Heatwave'],
            yticklabels=['Normal', 'Rain', 'Heavy Rain', 'Heatwave'], cbar_kws={'label': 'Count'})
plt.title('Confusion Matrix', fontsize=16, pad=15)
plt.xlabel('Predicted', fontsize=12)
plt.ylabel('Actual', fontsize=12)
plt.grid(False)
plt.tight_layout()
plt.show()

# ROC Curve (for multi-class)
plt.figure(figsize=(10, 6))
colors = plt.cm.Set2.colors
for i in range(4):
    fpr, tpr, _ = roc_curve(y_test == i, xgb_model.predict_proba(X_test)[:, i])
    roc_auc = auc(fpr, tpr)
    plt.plot(fpr, tpr, color=colors[i % len(colors)], lw=2, label=f'Class {i} (AUC = {roc_auc:.2f})')
plt.plot([0, 1], [0, 1], color='black', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.title('ROC Curve for Multi-Class', fontsize=16, pad=15)
plt.xlabel('False Positive Rate', fontsize=12)
plt.ylabel('True Positive Rate', fontsize=12)
plt.legend(fontsize=10)
plt.grid(True, linestyle='--', alpha=0.7)
plt.tight_layout()
plt.show()

# Saving the model
with open('xgboost_weather_model.pkl', 'wb') as f:
    pickle.dump(xgb_model, f)
print("Model saved as 'xgboost_weather_model.pkl'")

# Saving as .pt file (serializing XGBoost booster)
booster = xgb_model.get_booster()
state_dict = {'booster': booster.save_raw()}
torch.save(state_dict, 'xgboost_weather_model.pt')
print("Model saved as 'xgboost_weather_model.pt'")

