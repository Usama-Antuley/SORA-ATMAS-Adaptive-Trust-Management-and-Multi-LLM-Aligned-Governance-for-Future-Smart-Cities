# -*- coding: utf-8 -*-
"""SORA.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1V7u0tX4HvxXRaWb04912NdPJCWqL1MRu
"""

import hashlib
import json
from datetime import datetime
import uuid

class SORA:
    """
    SORA (Security & Operational Response Agent) Governance Engine.
    Implements validation, selection, feedback, policy enforcement, and consolidated alerting
    for a multi-agent smart-city disaster management system.
    """

    def __init__(self,
                 theta_r: float = 0.7,
                 theta_t: float = 0.5,
                 tau_t: Dict[str, float] = None,
                 epsilon_r: float = 0.1,
                 epsilon_t: float = 0.1,
                 mae_tie_tolerance: float = 0.01,
                 hysteresis: float = 0.05,
                 cooldown: int = 300) -> None:
        """
        Initialize SORA with policy configurations.

        :param theta_r: Risk threshold for restriction.
        :param theta_t: Trust threshold for denial.
        :param tau_t: Domain-specific trust baselines.
        :param epsilon_r: Tolerance for risk delta in admission.
        :param epsilon_t: Tolerance for trust delta in admission.
        :param mae_tie_tolerance: Tolerance for considering MAE as tied.
        :param hysteresis: Hysteresis value for escalation thresholds.
        :param cooldown: Cooldown period in seconds for repeated escalations.
        """
        self.theta_r = theta_r
        self.theta_t = theta_t
        self.tau_t = tau_t or {
            "Weather": 0.60,
            "Traffic": 0.55,
            "Safety": 0.65
        }
        self.epsilon_r = epsilon_r
        self.epsilon_t = epsilon_t
        self.mae_tie_tolerance = mae_tie_tolerance
        self.hysteresis = hysteresis
        self.cooldown = cooldown
        # Mock state for hysteresis and cooldown (in production, persist via DB)
        self.last_escalation_time: Optional[datetime.datetime] = None
        self.previous_escalation: bool = False
                     
    def compute_sora_reference(self, agent_packet: Dict[str, Any]) -> Tuple[float, float]:
        """
        Recompute reference risk (R_ref) and trust (T_ref) using Definitions 1-7.

        Definition 1: For Weather, R_weather = mapping of predicted_label to risk value.
        Definition 2: For Weather, T_weather = domain baseline trust.
        Definition 3: For Traffic, R_traffic = normalized vehicle_count (clipped to [0,1]).
        Definition 4: For Traffic, T_traffic = domain baseline trust.
        Definition 5: For Safety, R_safety = 1.0 if fire and smoke, 0.9 if fire only, 0.8 if smoke only, else 0.0.
        Definition 6: For Safety, T_safety = domain baseline trust.
        Definition 7: R_ref = domain-specific R, T_ref = domain-specific T.

        :param agent_packet: Input packet from agent.
        :return: Tuple of (R_ref, T_ref).
        """
        agent_id = agent_packet["agent_id"]
        metadata = agent_packet["metadata"]
        if agent_id == "Weather":
            predicted_label = metadata.get("predicted_label", "Unknown")
            r_map = {"Normal": 0.0, "Flood": 0.9, "Heatwave": 0.7}
            r_ref = r_map.get(predicted_label, 0.5)  # Definition 1
            t_ref = self.tau_t["Weather"]  # Definition 2
        elif agent_id == "Traffic":
            vehicle_count = metadata.get("vehicle_count", 0)
            r_ref = min(vehicle_count / 50.0, 1.0)  # Definition 3 (assuming 50 as congestion threshold)
            t_ref = self.tau_t["Traffic"]  # Definition 4
        elif agent_id == "Safety":
            fire_detected = metadata.get("fire_detected", False)
            smoke_detected = metadata.get("smoke_detected", False)
            if fire_detected and smoke_detected:
                r_ref = 1.0
            elif fire_detected:
                r_ref = 0.9
            elif smoke_detected:
                r_ref = 0.8
            else:
                r_ref = 0.0  # Definition 5
            t_ref = self.tau_t["Safety"]  # Definition 6
        else:
            raise ValueError(f"Unknown agent_id: {agent_id}")
        return r_ref, t_ref  # Definition 7

    def admission_gate(self, agent_packet: Dict[str, Any]) -> bool:
        """
        S1: Validate agent packet for admission.

        Rules:
        - Compute R_ref, T_ref (Definitions 1-7).
        - ΔR = |R_ref - R_overall|, ΔT = |T_ref - T_overall|.
        - Reject if |ΔR| > ε_R or |ΔT| > ε_T.
        - Reject if T_overall < τ_T for the domain.
        - Log rejection reason (printed for audit).

        :param agent_packet: Input packet from agent.
        :return: True if admitted, False otherwise.
        """
        r_overall = agent_packet["R_overall"]
        t_overall = agent_packet["T_overall"]
        agent_id = agent_packet["agent_id"]
        r_ref, t_ref = self.compute_sora_reference(agent_packet)
        delta_r = abs(r_ref - r_overall)
        delta_t = abs(t_ref - t_overall)
        if t_overall < self.tau_t[agent_id]:
            print(f"Rejection: T_overall {t_overall} < τ_T {self.tau_t[agent_id]} for {agent_id}")
            return False
        if delta_r > self.epsilon_r or delta_t > self.epsilon_t:
            print(f"Rejection: ΔR {delta_r} > ε_R {self.epsilon_r} or ΔT {delta_t} > ε_T {self.epsilon_t} for {agent_id}")
            return False
        return True

    def select_llm(self, llm_outputs: List[Dict[str, Any]], r_ref: float, t_ref: float) -> Dict[str, Any]:
        """
        S2: Select best LLM output using MAE.

        MAE = 0.5 * (|R_j - R_ref| + |T_j - T_ref|)
        Selection:
        - Minimum MAE.
        - Tie (within tolerance): select closest risk (|R_j - R_ref|).
        - Safety fallback: If selected T < τ_T, select nearest T >= τ_T (min |T_j - t_ref| among qualifiers).

        :param llm_outputs: List of LLM outputs.
        :param r_ref: Reference risk.
        :param t_ref: Reference trust.
        :return: Selected LLM dict.
        """
        if not llm_outputs:
            raise ValueError("No LLM outputs provided.")

        def mae(r: float, t: float) -> float:
            return 0.5 * (abs(r - r_ref) + abs(t - t_ref))

        # Compute MAE for each
        scored = [(mae(out["R"], out["T"]), abs(out["R"] - r_ref), out) for out in llm_outputs]
        min_mae = min(s[0] for s in scored)
        candidates = [s for s in scored if abs(s[0] - min_mae) <= self.mae_tie_tolerance]
        # Sort by closest risk (secondary key)
        candidates.sort(key=lambda s: s[1])
        selected = candidates[0][2]

        # Safety fallback
        tau_t = self.tau_t[selected["model"]] if "model" in selected else 0.5  # Fallback, but use domain? Wait, tau_t is domain, but per model?
        # Assume tau_t is domain, but since not per model, use general theta_t for fallback.
        if selected["T"] < self.theta_t:
            qualifiers = [out for out in llm_outputs if out["T"] >= self.theta_t]
            if qualifiers:
                # Nearest to t_ref
                qualifiers.sort(key=lambda out: abs(out["T"] - t_ref))
                selected = qualifiers[0]

        return selected

    def generate_feedback(self, llm_output: Dict[str, Any], r_ref: float, t_ref: float) -> Dict[str, Any]:
        """
        S3: Generate corrective feedback for an LLM output.

        ΔR = r_ref - R_j, ΔT = t_ref - T_j
        Apply 50% correction, clip to [0,1].
        Does NOT update model parameters (feedback for logging/audit).

        :param llm_output: Single LLM output.
        :param r_ref: Reference risk.
        :param t_ref: Reference trust.
        :return: Feedback packet.
        """
        delta_r = r_ref - llm_output["R"]
        delta_t = t_ref - llm_output["T"]
        corrected_r = max(0.0, min(1.0, llm_output["R"] + 0.5 * delta_r))
        corrected_t = max(0.0, min(1.0, llm_output["T"] + 0.5 * delta_t))
        return {
            "model": llm_output["model"],
            "delta_r": delta_r,
            "delta_t": delta_t,
            "corrected_r": corrected_r,
            "corrected_t": corrected_t,
            "explanation": f"Applied 50% correction based on reference (Definitions 1-7)."
        }

    def policy_decision(self, r: float, t: float) -> str:
        """
        Policy decision based on R and T.

        - Deny if T < θ_T
        - Restrict if R > θ_R
        - Approve otherwise
        Domain-aware overrides can be added here.

        :param r: Risk value.
        :param t: Trust value.
        :return: Decision string.
        """
        if t < self.theta_t:
            return "deny"
        if r > self.theta_r:
            return "restrict"
        return "approve"

    def process_agent(self, agent_packet: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """
        Process a single agent packet through S1-S3.

        :param agent_packet: Agent input.
        :return: Governance output if admitted, else None.
        """
        if not self.admission_gate(agent_packet):
            return None
        r_ref, t_ref = self.compute_sora_reference(agent_packet)
        selected = self.select_llm(agent_packet["llm_outputs"], r_ref, t_ref)
        decision = self.policy_decision(selected["R"], selected["T"])
        justification = (
            f"Risk driver: {selected['R']} (ref {r_ref}, Definition 4/6). "
            f"Trust driver: {selected['T']} (ref {t_ref}, Definition 6). "
            f"Agent domain: {agent_packet['agent_id']}. "
            f"Predicted regime: {agent_packet['metadata'].get('predicted_label', 'N/A')} (Weather only)."
        )
        gov_output = {
            "decision": decision,
            "justification": justification,
            "selected_model": selected["model"],
            "risk": selected["R"],
            "trust": selected["T"]
        }
        # Generate feedback for all LLMs (for audit)
        feedbacks = [self.generate_feedback(out, r_ref, t_ref) for out in agent_packet["llm_outputs"]]
        # Anchor agent decision (mock)
        self.anchor_agent_chain(gov_output)
        return gov_output

    def ecosystem_evaluation(self, agent_decisions: List[Dict[str, Any]], current_time: datetime.datetime) -> Dict[str, Any]:
        """
        S4-S6: Evaluate cross-agent ecosystem.

        Rules:
        - Joint actuation if >=2 agents with R > 0.80.
        - R_ecosystem = max(R_i)
        - T_ecosystem = mean(T_i)
        - Escalation if R_ecosystem > 0.70 AND T_ecosystem >= 0.60 (with hysteresis/cooldown).

        :param agent_decisions: List of per-agent decisions.
        :param current_time: Current timestamp.
        :return: Ecosystem metrics.
        """
        if not agent_decisions:
            return {"R_ecosystem": 0.0, "T_ecosystem": 0.0, "escalation": False}

        r_values = [d["risk"] for d in agent_decisions]
        t_values = [d["trust"] for d in agent_decisions]
        r_eco = max(r_values)
        t_eco = sum(t_values) / len(t_values)
        high_r_count = sum(1 for r in r_values if r > 0.80)
        joint_actuation = high_r_count >= 2

        # Hysteresis: lower threshold if previous escalation
        effective_r_threshold = 0.70 - self.hysteresis if self.previous_escalation else 0.70
        effective_t_threshold = 0.60

        # Cooldown check
        if self.last_escalation_time and (current_time - self.last_escalation_time).total_seconds() < self.cooldown:
            escalation = False
        else:
            escalation = r_eco > effective_r_threshold and t_eco >= effective_t_threshold

        if escalation:
            self.last_escalation_time = current_time
            self.previous_escalation = True
        else:
            self.previous_escalation = False

        return {
            "R_ecosystem": r_eco,
            "T_ecosystem": t_eco,
            "joint_actuation": joint_actuation,
            "escalation": escalation
        }

    def generate_city_alert(self,
                            agent_decisions: List[Dict[str, Any]],
                            timestamp: str,
                            location: Dict[str, Any],
                            ecosystem: Dict[str, Any]) -> Dict[str, Any]:
        """
        Generate mandatory consolidated city-level alert.

        Semantics:
        - Safety hazards precedence.
        - Traffic/Weather as secondary.
        - Directive for emergency services, audit, public.

        :param agent_decisions: Per-agent decisions.
        :param timestamp: Timestamp.
        :param location: Location dict.
        :param ecosystem: Ecosystem metrics.
        :return: Alert dict.
        """
        # Determine primary hazard (Safety precedence)
        safety_dec = next((d for d in agent_decisions if d.get("agent_id", "") == "Safety"), None)  # Add agent_id to decisions?
        # Wait, agent_decisions have no agent_id, fix by adding in process_agent.
        # For example, assume order: Weather, Traffic, Safety
        weather_dec, traffic_dec, safety_dec = agent_decisions  # Assume order for example

        primary_type = "None"
        confidence = "Low"
        primary_action = "Monitor"

        # Safety
        if safety_dec["risk"] > 0.7:
            primary_type = "Fire" if safety_dec["risk"] >= 0.9 else "Smoke"
            confidence = "High" if safety_dec["trust"] >= 0.7 else "Medium" if safety_dec["trust"] >= 0.5 else "Low"
            primary_action = "Evacuate" if safety_dec["risk"] > 0.9 else "Dispatch"

        # Secondary
        secondary = []
        if weather_dec["risk"] > 0.5:
            secondary.append({
                "type": "Weather",
                "severity": f"{weather_dec['risk']:.2f}",
                "action": "Advisory" if weather_dec["risk"] > 0.7 else "None"
            })
        if traffic_dec["risk"] > 0.5:
            secondary.append({
                "type": "Traffic",
                "severity": f"{traffic_dec['risk']:.2f}",
                "action": "Reroute" if traffic_dec["risk"] > 0.7 else "None"
            })

        gov_decision = "Emergency Escalation" if ecosystem["escalation"] else "Advisory" if max(d["risk"] for d in agent_decisions) > 0.5 else "No Action"
        policy_just = f"Escalation based on R_ecosystem {ecosystem['R_ecosystem']:.2f} > 0.70 and T_ecosystem {ecosystem['T_ecosystem']:.2f} >= 0.60 (with hysteresis {self.hysteresis}). Policy: restrict high risk."
        final_directive = f"Immediate {primary_action} to {location['zone']} due to {primary_type}. Reroute traffic if applicable. Monitor secondary conditions."

        alert = {
            "timestamp": timestamp,
            "location": location,
            "primary_hazard": {
                "type": primary_type,
                "confidence": confidence,
                "action": primary_action
            },
            "secondary_conditions": secondary,
            "ecosystem_metrics": {
                "R_ecosystem": ecosystem["R_ecosystem"],
                "T_ecosystem": ecosystem["T_ecosystem"]
            },
            "governance_decision": gov_decision,
            "policy_justification": policy_just,
            "final_directive": final_directive
        }
        # Anchor SORA alert (mock)
        self.anchor_sora_chain(alert)
        return alert

    def anchor_agent_chain(self, record: Dict[str, Any]) -> str:
        """
        Mock blockchain anchoring for agent record.

        :param record: Decision record.
        :return: Mock tx ID.
        """
        serialized = json.dumps(record, sort_keys=True)
        mock_tx_id = f"agent_tx_{hash(serialized) % 1000000}"
        print(f"Anchored agent record: {mock_tx_id}")
        return mock_tx_id

    def anchor_sora_chain(self, record: Dict[str, Any]) -> str:
        """
        Mock blockchain anchoring for SORA record.

        :param record: Alert record.
        :return: Mock tx ID.
        """
        serialized = json.dumps(record, sort_keys=True)
        mock_tx_id = f"sora_tx_{hash(serialized) % 1000000}"
        print(f"Anchored SORA record: {mock_tx_id}")
        return mock_tx_id


    def load_agent_results(agent_name):
        models = [
        ("gpt-4o-nano", f"{agent_name}_Results_gpt4onano.xlsx"),
        ("deepseek-r1", f"{agent_name}_Results_deepseekr1.xlsx"),
        ("grok",        f"{agent_name}_Results_grok.xlsx"),
        ]
    
        llm_outputs = []
        r_total = 0.0
        t_total = 0.0
        count = 0
        metadata = {}
    
        for model_name, filename in models:
            filepath = os.path.join("results", filename)
            if not os.path.exists(filepath):
                print(f"File not found: {filepath}")
                continue
                try:
                    df = pd.read_excel(filepath)
                    row = df.iloc[0]  # first row
            
                    # Find R_Overall and T_Overall columns (flexible name matching)
                    r_col = next((c for c in df.columns if "r_overall" in c.lower()), None)
                    t_col = next((c for c in df.columns if "t_overall" in c.lower()), None)
            
                    if r_col is None or t_col is None:
                        print(f"  Warning: Missing R/T columns in {filename}")
                        continue
                
                        r = float(row[r_col])
                        t = float(row[t_col])
            
                        llm_outputs.append({
                            "model": model_name,
                            "R": r,
                            "T": t,
                            "explanation": row.get("Final Comment", "No explanation")})
            
                        r_total += r
                        t_total += t
                        count += 1
            
                        if agent_name == "Weather" and "predicted_label" in df.columns:
                            metadata["predicted_label"] = str(row["predicted_label"])
                        elif agent_name == "Traffic" and "vehicle_count" in df.columns:
                            metadata["vehicle_count"] = float(row["vehicle_count"])
                        elif agent_name == "Safety":
                            if "class" in df.columns:
                                metadata["class"] = str(row["class"])
                                if "fire_detected" in df.columns:
                                    metadata["fire_detected"] = bool(row["fire_detected"])
                                if "smoke_detected" in df.columns:
                                    metadata["smoke_detected"] = bool(row["smoke_detected"]) 
                except Exception as e:
                    print(f"Error loading {filename}: {e}")
    
        if count == 0:
            print(f"ERROR: No data loaded for {agent_name}")
            # Fallback to avoid crash - use mock values
            return {
                "agent_id": agent_name,
                "timestamp": timestamp,
                "R_overall": 0.5,
                "T_overall": 0.6,
                "llm_outputs": [],
                "metadata": {}
            }
        return {
            "agent_id": agent_name,
            "timestamp": timestamp,
            "R_overall": r_total / count,
            "T_overall": t_total / count,
            "llm_outputs": llm_outputs,
            "metadata": metadata
        }

# mc_clients = { ... }   # your existing clients

# New / extended constant
GENERATIVE_STREAM = "GenerativeLog"

# Helper to initialize the stream if needed (safe to call multiple times)
def ensure_generative_stream(mc_client):
    try:
        # Check if stream exists
        info = mc_client.liststreams(GENERATIVE_STREAM)
        if not info:
            print(f"Creating stream {GENERATIVE_STREAM}...")
            mc_client.createstream(GENERATIVE_STREAM, True)  # open = True
            mc_client.subscribe(GENERATIVE_STREAM)
    except Exception as e:
        print(f"Could not ensure {GENERATIVE_STREAM} stream: {e}")


# ================== New function - logging generative AI activity ==================
def log_generative_activity(mc_clients, service_id, context, llm_data=None, sora_data=None):
    """
    Logs LLM calls and Sora generations to a dedicated MultiChain stream
    """
    if not MULTICHAIN_AVAILABLE:
        print("MultiChain not available - skipping generative log")
        return

    timestamp = datetime.utcnow().isoformat() + "Z"
    
    entry = {
        "timestamp": timestamp,
        "service_id": service_id,
        "uuid": str(uuid.uuid4())[:8],          # short unique id
        "context": context,                     # e.g. "city_alert", "irrigation_decision", etc.
        
        # LLM related
        "llm": llm_data or None,                # can be dict: {"prompt": ..., "output": ..., "model": ..., "tokens": ...}
        
        # Sora / video generation related
        "sora": sora_data or None,              # dict: {"prompt": ..., "video_path": ..., "status": "success"/"failed", "duration_sec": ..., "error": ...}
    }

    # Clean None values if you prefer
    if entry["llm"] is None:
        entry.pop("llm")
    if entry["sora"] is None:
        entry.pop("sora")

    for name, client in mc_clients.items():
        try:
            ensure_generative_stream(client)  # idempotent
            
            client.publish(GENERATIVE_STREAM, 
                          [service_id, timestamp.replace(":", "-")[:19]],  # rough key for ordering
                          {"json": entry})
            
            print(f"→ Published generative log to {name}/{GENERATIVE_STREAM}")
        except Exception as e:
            print(f"Failed to publish generative log to {name}: {e}")

if __name__ == "__main__":
    sora = SORA()  

    # Load agent results
    weather_packet = load_agent_results("Weather")
    traffic_packet = load_agent_results("Traffic")
    safety_packet = load_agent_results("Safety")

    agent_packets = [weather_packet, traffic_packet, safety_packet]
    agent_decisions = []

    # Process each agent and collect generative metadata
    for packet in agent_packets:
        decision = sora.process_agent(packet)
        if decision:
            decision["agent_id"] = packet["agent_id"]  # Add for later reference
            agent_decisions.append(decision)

    # Ecosystem evaluation
    current_time = datetime.datetime.fromisoformat(timestamp.replace("Z", "+00:00"))
    ecosystem = sora.ecosystem_evaluation(agent_decisions, current_time)

    # Generate final alert
    alert = sora.generate_city_alert(agent_decisions, timestamp, location, ecosystem)

    # Output the final alert
    print(json.dumps(alert, indent=2))

    # Inline comments on example:
    # Escalation occurred because R_ecosystem = max(0.0, 0.4, 1.0) = 1.0 > 0.70 and T_ecosystem = mean(0.60, 0.55, 0.65) = 0.60 >= 0.60.
    # Policy fired: restrict since Safety R=1.0 > θ_R=0.7, but ecosystem escalation overrides to Emergency Escalation.
    # Final directive justified: Safety hazard (Fire) takes precedence, high confidence due to T=0.65 >0.5, action Evacuate as R>0.9; suitable for emergency response, audit (traceable to Definitions 1-7 and policies), and public alerting.
